# Process AC:NH data

```{r setup, include=FALSE}
library(pacman)
p_load(
  readxl,
  knitr,
  here,
  lubridate,
  scales,
  tidyverse
)
# remotes::install_github("rubenarslan/formr")
p_load(formr)
opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE, 
  cache = TRUE
)
```

Here, we process the AC:NH survey and telemetry files.

Currently this script pulls survey data from formr.org, and saves to `data-raw/noa/`. If data already exists there, then it is loaded instead.

Telemetry data doesn't exist yet.

After processing, we place the processed data sets in `data/noa/` as R data objects.

## Process formr surveys

### Get raw data

Ensure output directories exists

```{r}
dir.create("data-raw/", FALSE)
dir.create("data-raw/noa/", FALSE)
dir.create("data/", FALSE)
dir.create("data/noa/", FALSE)
```

Read data from formr.org and save to `data-raw/` if it doesn't yet exist. For now you have to manually authenticate to formr if needed, sorry.

```{r}
if (!file.exists(here("data-raw/noa/formr.rds"))) {
  formr_connect()
  # These are the surveys
  surveys <- c("gaming_welcome", paste0("gaming_block", 2:5))
  # List of surveys' data frames
  ac <- map(surveys, ~formr_results(.) %>% as_tibble)
  saveRDS(ac, here("data-raw/noa/formr.rds"))
} else {ac <- readRDS(here("data-raw/noa/formr.rds"))}
```

Take only responses after the survey went live (i.e. take out our test sessions). Later, to make sure, we need to retain only rows where `code` exists in telemetry.

```{r}
ac[[1]] <- ac[[1]] %>% filter(created >= ymd("2020-10-27"))
```

Then, retain only rows where code exists, and consent & age check out

```{r}
# Keep only surveys whose code exists in gaming_welcome$code
ac[[1]] <- filter(
  ac[[1]], !is.na(code), of_age==1, consent_data==1, consent==1
)
```

Now apply those exclusions to all five survey data frames

```{r}
ac <- map(ac, ~filter(., code %in% ac[[1]][["code"]]))
```

Take out all time variables except first created and last ended (when survey started and ended)

```{r}
ac[[1]] <- select(ac[[1]], -c(modified:expired))
ac[2:4] <- map(ac[2:4], ~select(., -c(created:expired)))
ac[[5]] <- select(ac[[5]], -c(created, modified, expired))
```

Put all five survey's responses on one row per participant

```{r}
ac <- ac %>% reduce(left_join)
glimpse(ac)
glimpse(as_factor(ac))
```

Create a file with codes (hashed ID) and when survey started

```{r eval = FALSE}
select(ac, code, survey_start = created) %>% 
  arrange(survey_start) %>% 
  write_csv(here(str_glue("ID---{Sys.time()}.csv")))
```

Because we only keep telemetry data of players who answered the survey, we'll get a variable with the IDs of ppl who filled survey

```{r}
survey_ids <- pull(ac, code) 
```


### Clean survey data

- Create duration variable
- give some sensible variable names
- assign proper variable types

```{r}
# Duration of survey
ac <- ac %>% 
  mutate(
    survey_duration = ended-created
  )
# Create variables for straightliners by checking if variance within a block of questions is zero
ac$straightliner_spane <- apply(
  select(ac, starts_with("spane_") & !starts_with("spane_acnh")), 
  1, sd, na.rm = TRUE
)
ac$straightliner_spane <- ac$straightliner_spane==0
ac$straightliner_motivations <- apply(
  select(
    ac, 
    starts_with("autonomy_"), 
    starts_with("competence_"), 
    starts_with("related_"), 
    starts_with("enjoymen_"), 
    starts_with("extrinsic_")
  ), 
  1, sd, na.rm = TRUE
)
ac$straightliner_motivations <- ac$straightliner_motivations==0

# These are needed as factors
ac <- ac %>% 
  mutate(across(c(sex, played_with_others), as_factor))


# reverse scored items
ac <- ac %>% 
  mutate(
    across(
      c(
        related_not_close,
        enjoyment_attention,
        enjoymen_boring
      ),
      ~ 8 - .x
    )
  )
```

Next, let's create mean indices for the scales.
SPANE has positive affect, negative affect, and an affect balance score (subtract negative from positive).
```{r create-scales}
# Need to rename spane item so it doesnt become confused with sum score
ac <- rename(
  ac, 
  spane_positiveItem = spane_positive,
  spane_negativeItem = spane_negative
)

# general spane
ac <- ac %>% 
  mutate(
    spane_positive = rowSums(
      select(
        .,
        spane_positiveItem,
        spane_good,
        spane_pleasant,
        spane_happy,
        spane_joyful,
        spane_contented
      ),
      na.rm = TRUE
    ),
    spane_negative = rowSums(
      select(
        .,
        spane_negativeItem,
        spane_bad,
        spane_unpleasant,
        spane_sad,
        spane_afraid,
        spane_angry
      ),
      na.rm = TRUE
    ),
    spane_balance = spane_positive - spane_negative
  )

# motivations
ac <- ac %>% mutate(
  autonomy = rowMeans(select(., starts_with("autonomy")), na.rm = TRUE),
  competence = rowMeans(select(., starts_with("competence")), na.rm = TRUE),
  relatedness = rowMeans(select(., starts_with("related")), na.rm = TRUE),
  enjoyment = rowMeans(select(., starts_with("enjoymen")), na.rm = TRUE),
  extrinsic = rowMeans(select(., starts_with("extrinsic")), na.rm = TRUE)
)

# spane because of playing AC:NH
ac <- ac %>% 
  mutate(
    spane_game_positive = rowSums(
      select(
        .,
        spane_acnh_positive,
        spane_acnh_good,
        spane_acnh_pleasant,
        spane_acnh_happy,
        spane_acnh_joyful,
        spane_acnh_contented
      ),
      na.rm = TRUE
    ),
    spane_game_negative = rowSums(
      select(
        .,
        spane_acnh_negative,
        spane_acnh_bad,
        spane_acnh_unpleasant,
        spane_acnh_sad,
        spane_acnh_afraid,
        spane_acnh_angry
      ),
      na.rm = TRUE
    ),
    spane_game_balance = spane_game_positive - spane_game_negative
  )

# hours of estimated play
ac <- ac %>% 
  mutate(
    active_play = active_play_hours + (active_play_minutes / 60)
  )
```

### Checking

Codes (Player IDs)

```{r}
count(ac, code, sort = T)
```

There are two kinds of problems:
1. No ID was captured
2. An ID was used more than once

For both cases, connecting to telemetry would be impossible (and wrong connections could be made in latter case), so we drop these cases

```{r}
ac <- add_count(ac, code) %>% 
  filter(n == 1) %>% 
  select(-n)
```

## Harmonize data to Study 1

Change some names to better match the other data

```{r}
ac <- rename(ac, player_id = code)
```

## Telemetry

We provided NOA with the hashed IDs of players who took the survey, they then sent us only those players telemetry.

```{r}
game_time <- read_tsv(here("data-raw/noa/telem_data.txt"))
```

Column definition	
lc_recorded_at = Session start date/time
nc_recorded_at = Session end date/time
nsa_id_hex [(now hashed_id)] = Hashed account ID
product_model =	Switch model game was played on
operation_mode = Identifies handheld mode, TV mode
duration = Duration of session (seconds)
storage_id = Whether game is played off game card, SD card or internal = system memory
application_id_hex = Game's hashed ID

We drop some unnecessary variables

```{r}
game_time <- select(
  game_time,
  hashed_id, 
  contains("recorded"),
  duration
)
```

Then rename

```{r}
names(game_time) <- c(
  "player_id", "session_start", "session_end", "Hours"
)
```

And turn duration into hours

```{r}
game_time$Hours <- game_time$Hours/60/60
```

Variable types

Assume that timestamps are US Pacific as this was used to report data collection dates & times.

```{r}
game_time <- game_time %>% 
  mutate(
    across(contains("session"), ~mdy_hm(.x, tz = "US/Pacific"))
  )
```

### Clean

We don't need to limit to IDs who took the survey as NOA has already done that--these data only contain folks who filled survey.

But we do need to limit the data to two weeks preceding the survey.

We therefore need to use the session start/end times to find out when the sessions happened.

There are now a bunch of questions related to this:

Why are lots of start and end times the same? Even though the duration is non-zero for those rows.

```{r}
prop.table(
  table(game_time$session_start==game_time$session_end)
)
summary(
  game_time$Hours
  [game_time$session_start==game_time$session_end]
)
```

Why are many start times before AC:NH was released?

```{r}
table(game_time$session_start < ymd("2020-03-20"))
table(game_time$session_end < ymd("2020-03-20"))
```

Here's a figure of all session start times (day of year) separately for each year. Also shown are when ACNH was released, and survey window, as vertical lines. We see here that lots of sessions happened prior to launch, and no sessions happened during survey window!

```{r}
game_time %>%
  mutate(
    year = year(session_start), yday = yday(session_start)
  ) %>% 
  ggplot(aes(yday)) +
  # Three lines note when AC:NH was released...
  geom_vline(
    xintercept = yday(ymd("2020-03-20")), col="red"
  ) +
  # When survey started
  geom_vline(
    xintercept = yday(ymd("2020-10-27")), col = "red"
  ) +
  # And two weeks preceding it
  geom_vline(
    xintercept = yday(ymd("2020-10-13")), col = "red"
  ) +
  geom_histogram() +
  facet_wrap("year", scales = "free_y")
```

Using the session end variable doesn't really help because so few sessions ended in the survey window

```{r}
game_time %>% 
  left_join(select(ac, player_id, created)) %>% 
  filter(session_end >= (created - days(14))) %>% 
  nrow(.)
```

But that's the only thing we can do so we go ahead with it.

```{r}
game_time <- game_time %>% 
  left_join(select(ac, player_id, created)) %>% 
  filter(session_end >= (created - days(14)))
```

We then summarize to total hours per person

```{r}
game_time <- game_time %>% 
  group_by(player_id) %>% 
  summarise(
    Hours = sum(Hours), 
    n_sessions = n()
  )
arrange(game_time, desc(Hours))
summary(game_time$Hours)
```

We are left with 37 people for whom telemetry exists in the survey window!

## Join survey and telemetry

```{r}
ac <- left_join(ac, game_time)
```

## Exclusions

First save a file with no exclusions

```{r}
write_rds(ac, here("data/noa/ac.rds"))
```

### Straightliners

We take out all individuals who straightlined (gave the same response to every item) thru SPANE or motivations questions

```{r}
table(ac$straightliner_motivations|ac$straightliner_spane)
prop.table(
  table(ac$straightliner_motivations|ac$straightliner_spane)
)
ac <- filter(ac, !straightliner_motivations)
ac <- filter(ac, !straightliner_spane)
```

### Outliers

Potential outliers. We replace all values that are more than 6SD away from the variable's mean with NAs. As a consequence, individuals are excluded on an analysis-by-analysis case (so if has bad data relevant to that analysis or figure).

This is only done for a subset of variables (relavant to analyses; see below)

```{r}
ac <- ac %>% 
  # These variables will be affected
  pivot_longer(
    c(
      spane_positiveItem:Hours, 
      -played_with_others, -ended, -survey_duration,
      -contains("straightliner")
    )
  ) %>% 
  group_by(name) %>% 
  mutate(z_value = as.numeric(scale(value))) 
```

These are the numbers of people taken out of each variable (only variables that were affected are shown):

```{r}
# This is what are taken out
ac %>% 
  summarise(
    Extremes = sum(abs(z_value>=6), na.rm = TRUE),
    Extremes_p = percent(Extremes/n(), accuracy = .01)
  ) %>% 
  filter(Extremes > 0)
```

Code to do it:

```{r}
ac <- ac %>%
  mutate(value = ifelse(abs(z_value >= 6), NA, value)) %>% 
  select(-z_value) %>% 
  pivot_wider(names_from = "name", values_from = "value") %>% 
  ungroup()
```

## Save files

```{r}
write_rds(ac, here("data/noa/ac-excluded.rds"))
```
